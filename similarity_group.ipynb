{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is used to reorder the task sequence and group similar/dissimilar classes within task"
      ],
      "metadata": {
        "id": "HBuCWM7mC6TG"
      },
      "id": "HBuCWM7mC6TG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e08a38d6-288a-4e81-b14f-82b153867cf7",
      "metadata": {
        "id": "e08a38d6-288a-4e81-b14f-82b153867cf7",
        "outputId": "2e5110f2-52e4-4453-d8f0-8841d1261619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cached /homes/55/enbo/.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /homes/55/enbo/.cache/facebookresearch_dino_main\n",
            "/homes/55/enbo/miniconda3/envs/thesis3.7/lib/python3.7/site-packages/peft/tuners/lora.py:144: UserWarning: fan_in_fan_out is set to True but the target module is not a Conv1D. Setting fan_in_fan_out to False.\n",
            "  \"fan_in_fan_out is set to True but the target module is not a Conv1D. \"\n"
          ]
        }
      ],
      "source": [
        "from dreamsim import dreamsim\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "\n",
        "cache_dir = os.path.expanduser(\"~/.cache\")\n",
        "model, preprocess = dreamsim(pretrained=True, cache_dir=cache_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3069469b-58f4-426d-82c2-2e965f9fa7f8",
      "metadata": {
        "id": "3069469b-58f4-426d-82c2-2e965f9fa7f8"
      },
      "outputs": [],
      "source": [
        "def compare_two_datasets(folder1, folder2):\n",
        "    \"\"\"\n",
        "    this function can be used to compare the perceptual distance between two\n",
        "    classes of images saving at different folders\n",
        "    \"\"\"\n",
        "    all_files1 = os.listdir(folder1)\n",
        "    all_files2 = os.listdir(folder2)\n",
        "\n",
        "    all_non_txt_files1 = [file for file in all_files1 if (file.endswith('.jpg') or file.endswith('.png'))]\n",
        "    all_non_txt_files2 = [file for file in all_files2 if (file.endswith('.jpg') or file.endswith('.png'))]\n",
        "\n",
        "    if set(all_non_txt_files1) != set(all_non_txt_files2):\n",
        "        print(\"items in the two folders do not match\")\n",
        "        return\n",
        "    else:\n",
        "        print(\"items in the two folders match, going to measure...\")\n",
        "\n",
        "    total_distance = 0\n",
        "    for i, files in enumerate(all_non_txt_files1):\n",
        "        img1 = preprocess(Image.open(os.path.join(folder1, files)))\n",
        "        img2 = preprocess(Image.open(os.path.join(folder2, files)))\n",
        "        if i%20 == 0:\n",
        "            print(i)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            img1 = img1.cuda()\n",
        "            img2 = img2.cuda()\n",
        "\n",
        "        distance = model(img1, img2)\n",
        "        total_distance += distance.item()\n",
        "\n",
        "    return total_distance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bffe2e5",
      "metadata": {
        "id": "3bffe2e5"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms.functional import pil_to_tensor\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "651641d6",
      "metadata": {
        "id": "651641d6"
      },
      "outputs": [],
      "source": [
        "test_dataset = datasets.MNIST('data', train=False, download=True)\n",
        "# from the mnist test_dataset to extract the class names\n",
        "name_list = test_dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd6c7789",
      "metadata": {
        "id": "cd6c7789",
        "outputId": "e0951b93-c576-406b-ed62-806d72dcfbbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['0 - zero',\n",
              " '1 - one',\n",
              " '2 - two',\n",
              " '3 - three',\n",
              " '4 - four',\n",
              " '5 - five',\n",
              " '6 - six',\n",
              " '7 - seven',\n",
              " '8 - eight',\n",
              " '9 - nine']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "name_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be56e974",
      "metadata": {
        "id": "be56e974"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "transform =transforms.Compose([\n",
        "                        #  transforms.RandomHorizontalFlip(),\n",
        "                         transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c81033a",
      "metadata": {
        "id": "1c81033a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torchvision.utils import save_image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def save_mnist(dataset, num_images_per_class, save_dir):\n",
        "    \"\"\"\n",
        "    this function is used to save samples of images from the dataset for comparison\n",
        "\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    saved_counts = {label: 0 for label in range(10)}  # Initialize saved image count for each class\n",
        "\n",
        "    for image, label in dataset:\n",
        "        if saved_counts[label] >= num_images_per_class:\n",
        "            continue\n",
        "\n",
        "        # Convert tensor image to PIL image and back to tensor to normalize\n",
        "        img = to_pil_image(image).convert(\"RGB\")\n",
        "        image_tensor = to_tensor(img)\n",
        "\n",
        "        class_name = dataset.classes[label].replace('/', '_')\n",
        "        class_dir = os.path.join(save_dir, class_name)\n",
        "\n",
        "        if not os.path.exists(class_dir):\n",
        "            os.makedirs(class_dir)\n",
        "\n",
        "        filename = f'image{saved_counts[label]}.png'\n",
        "        image_path = os.path.join(class_dir, filename)\n",
        "\n",
        "        save_image(image_tensor, image_path)\n",
        "        saved_counts[label] += 1\n",
        "\n",
        "        class_file_path = os.path.join(save_dir, f\"{class_name}.txt\")\n",
        "        with open(class_file_path, \"a\") as file:\n",
        "            file.write(f\"{image_path} {label}\\n\")\n",
        "\n",
        "        if all(count >= num_images_per_class for count in saved_counts.values()):\n",
        "            break\n",
        "\n",
        "    print(f\"Saved {num_images_per_class} images per class from the MNiST training dataset.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "479956bf",
      "metadata": {
        "id": "479956bf",
        "outputId": "586ac1a7-a7ab-41b3-95ec-0ba8cbfa70e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 20 images per class from the MNiST training dataset.\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.MNIST(root='data', train=True,\n",
        "                                         download=True, transform=transform)\n",
        "\n",
        "# save 20 images from the trainset for each class for comparison\n",
        "save_mnist(trainset, 20, 'mnist_10_0407')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffc6c6e2",
      "metadata": {
        "id": "ffc6c6e2"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def compare_class_pairs(base_dir, num_images=10):\n",
        "    classes = os.listdir(base_dir)\n",
        "    classes = [file for file in classes if not file.endswith('.txt')]\n",
        "    classes.sort()  # Ensure consistent order\n",
        "\n",
        "    distances = {}\n",
        "    # Use tqdm to track progress over classes\n",
        "    for i, class1 in tqdm(enumerate(classes[:-1]), total=len(classes[:-1]), desc=\"Comparing classes\"):\n",
        "        for class2 in classes[i+1:]:\n",
        "            class1_dir = os.path.join(base_dir, class1)\n",
        "            class2_dir = os.path.join(base_dir, class2)\n",
        "            total_distance = 0\n",
        "            for idx in range(num_images):\n",
        "                img1_path = os.path.join(class1_dir, f\"image{idx}.png\")\n",
        "                img2_path = os.path.join(class2_dir, f\"image{idx}.png\")\n",
        "\n",
        "                img1 = preprocess(Image.open(img1_path).convert(\"RGB\"))\n",
        "                img2 = preprocess(Image.open(img2_path).convert(\"RGB\"))\n",
        "\n",
        "                if torch.cuda.is_available():\n",
        "                    img1 = img1.cuda()\n",
        "                    img2 = img2.cuda()\n",
        "\n",
        "                distance = model(img1, img2)\n",
        "                total_distance += distance\n",
        "\n",
        "            average_distance = total_distance / num_images\n",
        "            distances[f\"{class1} vs {class2}\"] = average_distance\n",
        "\n",
        "    return distances\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbedde48",
      "metadata": {
        "id": "dbedde48",
        "outputId": "f35c1c8f-1ff5-43c3-ea16-91d79d881e27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Comparing classes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:43<00:00,  4.78s/it]\n"
          ]
        }
      ],
      "source": [
        "re = compare_class_pairs('mnist_10_0407', num_images=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff32c4e",
      "metadata": {
        "id": "bff32c4e",
        "outputId": "a689998a-a92f-4a0d-dba7-64df8b10fe36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'0 - zero vs 1 - one': tensor([0.3298], device='cuda:0'),\n",
              " '0 - zero vs 2 - two': tensor([0.2269], device='cuda:0'),\n",
              " '0 - zero vs 3 - three': tensor([0.2288], device='cuda:0'),\n",
              " '0 - zero vs 4 - four': tensor([0.3223], device='cuda:0'),\n",
              " '0 - zero vs 5 - five': tensor([0.2327], device='cuda:0'),\n",
              " '0 - zero vs 6 - six': tensor([0.2089], device='cuda:0'),\n",
              " '0 - zero vs 7 - seven': tensor([0.2764], device='cuda:0'),\n",
              " '0 - zero vs 8 - eight': tensor([0.2260], device='cuda:0'),\n",
              " '0 - zero vs 9 - nine': tensor([0.2293], device='cuda:0'),\n",
              " '1 - one vs 2 - two': tensor([0.2964], device='cuda:0'),\n",
              " '1 - one vs 3 - three': tensor([0.3195], device='cuda:0'),\n",
              " '1 - one vs 4 - four': tensor([0.2813], device='cuda:0'),\n",
              " '1 - one vs 5 - five': tensor([0.2837], device='cuda:0'),\n",
              " '1 - one vs 6 - six': tensor([0.2917], device='cuda:0'),\n",
              " '1 - one vs 7 - seven': tensor([0.2585], device='cuda:0'),\n",
              " '1 - one vs 8 - eight': tensor([0.3159], device='cuda:0'),\n",
              " '1 - one vs 9 - nine': tensor([0.2939], device='cuda:0'),\n",
              " '2 - two vs 3 - three': tensor([0.1842], device='cuda:0'),\n",
              " '2 - two vs 4 - four': tensor([0.2436], device='cuda:0'),\n",
              " '2 - two vs 5 - five': tensor([0.1827], device='cuda:0'),\n",
              " '2 - two vs 6 - six': tensor([0.2079], device='cuda:0'),\n",
              " '2 - two vs 7 - seven': tensor([0.2281], device='cuda:0'),\n",
              " '2 - two vs 8 - eight': tensor([0.2365], device='cuda:0'),\n",
              " '2 - two vs 9 - nine': tensor([0.2189], device='cuda:0'),\n",
              " '3 - three vs 4 - four': tensor([0.2673], device='cuda:0'),\n",
              " '3 - three vs 5 - five': tensor([0.1720], device='cuda:0'),\n",
              " '3 - three vs 6 - six': tensor([0.2132], device='cuda:0'),\n",
              " '3 - three vs 7 - seven': tensor([0.2452], device='cuda:0'),\n",
              " '3 - three vs 8 - eight': tensor([0.2367], device='cuda:0'),\n",
              " '3 - three vs 9 - nine': tensor([0.2247], device='cuda:0'),\n",
              " '4 - four vs 5 - five': tensor([0.2431], device='cuda:0'),\n",
              " '4 - four vs 6 - six': tensor([0.2599], device='cuda:0'),\n",
              " '4 - four vs 7 - seven': tensor([0.2415], device='cuda:0'),\n",
              " '4 - four vs 8 - eight': tensor([0.2609], device='cuda:0'),\n",
              " '4 - four vs 9 - nine': tensor([0.2586], device='cuda:0'),\n",
              " '5 - five vs 6 - six': tensor([0.1834], device='cuda:0'),\n",
              " '5 - five vs 7 - seven': tensor([0.2235], device='cuda:0'),\n",
              " '5 - five vs 8 - eight': tensor([0.2105], device='cuda:0'),\n",
              " '5 - five vs 9 - nine': tensor([0.2018], device='cuda:0'),\n",
              " '6 - six vs 7 - seven': tensor([0.2458], device='cuda:0'),\n",
              " '6 - six vs 8 - eight': tensor([0.2027], device='cuda:0'),\n",
              " '6 - six vs 9 - nine': tensor([0.1786], device='cuda:0'),\n",
              " '7 - seven vs 8 - eight': tensor([0.2602], device='cuda:0'),\n",
              " '7 - seven vs 9 - nine': tensor([0.2221], device='cuda:0'),\n",
              " '8 - eight vs 9 - nine': tensor([0.1819], device='cuda:0')}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf8f44f5",
      "metadata": {
        "id": "bf8f44f5",
        "outputId": "6ed3a4e5-da1e-429e-b4dd-8107baa97e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average of the tensors: 0.24127596616744995\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# total_sum = torch.tensor([0.0], device='cuda:0')\n",
        "# for value in re.values():\n",
        "#     total_sum += value\n",
        "# average = total_sum / len(re)\n",
        "\n",
        "# print(\"Average of the tensors:\", average.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "970a6084",
      "metadata": {
        "id": "970a6084"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import squareform\n",
        "from sklearn.manifold import MDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ea9d4a8",
      "metadata": {
        "id": "4ea9d4a8",
        "outputId": "bbf73e3e-ccc1-40e9-bf88-2a50bba1d889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group 1: 2 - two, 3 - three\n",
            "Group 2: 5 - five, 8 - eight, 9 - nine\n",
            "Group 3: 1 - one\n",
            "Group 4: 0 - zero, 6 - six\n",
            "Group 5: 4 - four, 7 - seven\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(name_list)\n",
        "distance_matrix = np.zeros((num_classes, num_classes))\n",
        "\n",
        "\n",
        "for i, class1 in enumerate(name_list):\n",
        "    for j, class2 in enumerate(name_list):\n",
        "        if i == j:\n",
        "            continue\n",
        "        key = f\"{class1} vs {class2}\" if f\"{class1} vs {class2}\" in re else f\"{class2} vs {class1}\"\n",
        "        distance_matrix[i, j] = re[key]\n",
        "\n",
        "# # Since KMeans doesn't work directly with a distance matrix, we can use MDS to convert our distances into points\n",
        "# mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=42)\n",
        "# points = mds.fit_transform(distance_matrix)\n",
        "\n",
        "# # Cluster the points into 5 clusters\n",
        "# kmeans = KMeans(n_clusters=5, random_state=42).fit(points)\n",
        "# labels = kmeans.labels_\n",
        "\n",
        "# # Organize classes into groups based on cluster assignment\n",
        "# groups = {i: [] for i in range(5)}\n",
        "# for class_index, group_index in enumerate(labels):\n",
        "#     groups[group_index].append(name_list[class_index])\n",
        "\n",
        "# # Display the groups\n",
        "# for group, group_classes in groups.items():\n",
        "#     print(f\"Group {group + 1}: {', '.join(group_classes)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n1, n2 = 1, 6\n",
        "num_task = 5\n",
        "num_classes = 10"
      ],
      "metadata": {
        "id": "xUEpWOvHCP_r"
      },
      "id": "xUEpWOvHCP_r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5151ccf1",
      "metadata": {
        "id": "5151ccf1",
        "outputId": "fe2aed54-a9c5-4ff8-a7bc-07c6a061efe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group 1: 2 - two, 3 - three\n",
            "Group 2: 5 - five, 6 - six\n",
            "Group 3: 8 - eight, 9 - nine\n",
            "Group 4: 0 - zero, 4 - four\n",
            "Group 5: 7 - seven, 1 - one\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "from scipy.spatial.distance import squareform\n",
        "\n",
        "# Convert the distance matrix to condensed form since linkage function expects this format\n",
        "condensed_distance_matrix = squareform(distance_matrix)\n",
        "\n",
        "# Perform hierarchical clustering\n",
        "Z = linkage(condensed_distance_matrix, 'average')\n",
        "\n",
        "initial_clusters = fcluster(Z, t=num_task, criterion='maxclust')\n",
        "clusters = {i: [] for i in range(n1, n2)}  # Adjust based on actual initial cluster ids\n",
        "\n",
        "# Assign classes to initial clusters\n",
        "for class_index, cluster_id in enumerate(initial_clusters):\n",
        "    clusters[cluster_id].append(name_list[class_index])\n",
        "\n",
        "# Function to adjust clusters to have exactly five members\n",
        "def adjust_clusters(clusters):\n",
        "    final_groups = {}\n",
        "    group_id = 0\n",
        "    temp_group = []\n",
        "\n",
        "    for cluster_id, members in clusters.items():\n",
        "        for member in members:\n",
        "            temp_group.append(member)\n",
        "            if len(temp_group) == int(num_classes/num_task):  # Once we have 5 members, save the group and reset\n",
        "                final_groups[group_id] = temp_group\n",
        "                group_id += 1\n",
        "                temp_group = []\n",
        "\n",
        "    return final_groups\n",
        "\n",
        "# Adjust the clusters to ensure each has exactly five classes\n",
        "final_groups = adjust_clusters(clusters)\n",
        "\n",
        "# Display the groups\n",
        "for group_id, group_classes in final_groups.items():\n",
        "    print(f\"Group {group_id + 1}: {', '.join(group_classes)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c46155",
      "metadata": {
        "scrolled": true,
        "id": "66c46155",
        "outputId": "d7a0d26e-01b6-411c-b257-b6f5f7ab206f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: ['2 - two', '3 - three'],\n",
              " 1: ['5 - five', '6 - six'],\n",
              " 2: ['8 - eight', '9 - nine'],\n",
              " 3: ['0 - zero', '4 - four'],\n",
              " 4: ['7 - seven', '1 - one']}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0b044e6",
      "metadata": {
        "id": "b0b044e6"
      },
      "outputs": [],
      "source": [
        "\n",
        "task_similarity = [[0 for _ in range(num_task)] for _ in range(num_task)]\n",
        "\n",
        "for i in range(num_task):\n",
        "    for j in range(num_task):\n",
        "        if i == j:\n",
        "            continue  # Skip comparing the task with itself\n",
        "        # Calculate average distance between classes in task i and task j\n",
        "        total_distance = 0\n",
        "        count = 0\n",
        "        for class1 in final_groups[i]:\n",
        "            for class2 in final_groups[j]:\n",
        "                key = f\"{class1} vs {class2}\" if f\"{class1} vs {class2}\" in re else f\"{class2} vs {class1}\"\n",
        "                total_distance += re[key]\n",
        "                count += 1\n",
        "        average_distance = total_distance / count\n",
        "        task_similarity[i][j] = average_distance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa915d92",
      "metadata": {
        "id": "fa915d92",
        "outputId": "7bffd59e-b53e-4b71-9ea6-175f26480fae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0,\n",
              "  tensor([0.1939], device='cuda:0'),\n",
              "  tensor([0.2292], device='cuda:0'),\n",
              "  tensor([0.2417], device='cuda:0'),\n",
              "  tensor([0.2723], device='cuda:0')],\n",
              " [tensor([0.1939], device='cuda:0'),\n",
              "  0,\n",
              "  tensor([0.1984], device='cuda:0'),\n",
              "  tensor([0.2361], device='cuda:0'),\n",
              "  tensor([0.2611], device='cuda:0')],\n",
              " [tensor([0.2292], device='cuda:0'),\n",
              "  tensor([0.1984], device='cuda:0'),\n",
              "  0,\n",
              "  tensor([0.2437], device='cuda:0'),\n",
              "  tensor([0.2730], device='cuda:0')],\n",
              " [tensor([0.2417], device='cuda:0'),\n",
              "  tensor([0.2361], device='cuda:0'),\n",
              "  tensor([0.2437], device='cuda:0'),\n",
              "  0,\n",
              "  tensor([0.2822], device='cuda:0')],\n",
              " [tensor([0.2723], device='cuda:0'),\n",
              "  tensor([0.2611], device='cuda:0'),\n",
              "  tensor([0.2730], device='cuda:0'),\n",
              "  tensor([0.2822], device='cuda:0'),\n",
              "  0]]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "task_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d69fd809",
      "metadata": {
        "id": "d69fd809"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def greedy_nearest_neighbors(task_similarity):\n",
        "    \"\"\"\n",
        "    A greedy approach to sequencing tasks based on minimizing the\n",
        "    distribution change between consecutive tasks.\n",
        "    \"\"\"\n",
        "    num_tasks = len(task_similarity)\n",
        "    visited = [False] * num_tasks\n",
        "    current_task = 0\n",
        "    task_order = [current_task]\n",
        "    visited[current_task] = True\n",
        "\n",
        "    while len(task_order) < num_tasks:\n",
        "        # Find the nearest unvisited task to the current task\n",
        "        next_task = None\n",
        "        min_change = float('inf')\n",
        "        for i in range(num_tasks):\n",
        "            if not visited[i] and task_similarity[current_task][i] < min_change:\n",
        "                next_task = i\n",
        "                min_change = task_similarity[current_task][i]\n",
        "        # Update the current task, mark it as visited, and add it to the task order\n",
        "        visited[next_task] = True\n",
        "        task_order.append(next_task)\n",
        "        current_task = next_task\n",
        "\n",
        "    return task_order\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "889029ac",
      "metadata": {
        "id": "889029ac",
        "outputId": "8590b8b6-838b-4a80-8c19-8db4cfec68cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Suggested task order to minimize distribution changes: [0, 1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "task_order = greedy_nearest_neighbors(task_similarity)\n",
        "\n",
        "print(\"Suggested task order to minimize distribution changes:\", task_order)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1258fe0d",
      "metadata": {
        "id": "1258fe0d"
      },
      "source": [
        "## dissimilarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a9f10e",
      "metadata": {
        "id": "b6a9f10e",
        "outputId": "88ec2835-317a-4bd5-9fd8-accd0949b21b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tasks with maximized dissimilarities:\n",
            "Task: ('8 - eight', '2 - two')\n",
            "Task: ('4 - four', '0 - zero')\n",
            "Task: ('3 - three', '1 - one')\n",
            "Task: ('9 - nine', '5 - five')\n",
            "Task: ('6 - six', '7 - seven')\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "# Sample data: distances between class pairs as provided\n",
        "distances = {\n",
        "    '0 - zero vs 1 - one': 0.3298,\n",
        "    '0 - zero vs 2 - two': 0.2269,\n",
        "    '0 - zero vs 3 - three': 0.2288,\n",
        "    '0 - zero vs 4 - four': 0.3223,\n",
        "    '0 - zero vs 5 - five': 0.2327,\n",
        "    '0 - zero vs 6 - six': 0.2089,\n",
        "    '0 - zero vs 7 - seven': 0.2764,\n",
        "    '0 - zero vs 8 - eight': 0.2260,\n",
        "    '0 - zero vs 9 - nine': 0.2293,\n",
        "    '1 - one vs 2 - two': 0.2964,\n",
        "    '1 - one vs 3 - three': 0.3195,\n",
        "    '1 - one vs 4 - four': 0.2813,\n",
        "    '1 - one vs 5 - five': 0.2837,\n",
        "    '1 - one vs 6 - six': 0.2917,\n",
        "    '1 - one vs 7 - seven': 0.2585,\n",
        "    '1 - one vs 8 - eight': 0.3159,\n",
        "    '1 - one vs 9 - nine': 0.2939,\n",
        "    '2 - two vs 3 - three': 0.1842,\n",
        "    '2 - two vs 4 - four': 0.2436,\n",
        "    '2 - two vs 5 - five': 0.1827,\n",
        "    '2 - two vs 6 - six': 0.2079,\n",
        "    '2 - two vs 7 - seven': 0.2281,\n",
        "    '2 - two vs 8 - eight': 0.2365,\n",
        "    '2 - two vs 9 - nine': 0.2189,\n",
        "    '3 - three vs 4 - four': 0.2673,\n",
        "    '3 - three vs 5 - five': 0.1720,\n",
        "    '3 - three vs 6 - six': 0.2132,\n",
        "    '3 - three vs 7 - seven': 0.2452,\n",
        "    '3 - three vs 8 - eight': 0.2367,\n",
        "    '3 - three vs 9 - nine': 0.2247,\n",
        "    '4 - four vs 5 - five': 0.2431,\n",
        "    '4 - four vs 6 - six': 0.2599,\n",
        "    '4 - four vs 7 - seven': 0.2415,\n",
        "    '4 - four vs 8 - eight': 0.2609,\n",
        "    '4 - four vs 9 - nine': 0.2586,\n",
        "    '5 - five vs 6 - six': 0.1834,\n",
        "    '5 - five vs 7 - seven': 0.2235,\n",
        "    '5 - five vs 8 - eight': 0.2105,\n",
        "    '5 - five vs 9 - nine': 0.2018,\n",
        "    '6 - six vs 7 - seven': 0.2458,\n",
        "    '6 - six vs 8 - eight': 0.2027,\n",
        "    '6 - six vs 9 - nine': 0.1786,\n",
        "    '7 - seven vs 8 - eight': 0.2602,\n",
        "    '7 - seven vs 9 - nine': 0.2221,\n",
        "    '8 - eight vs 9 - nine': 0.1819\n",
        "}\n",
        "\n",
        "# Create a complete graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add edges between classes with their dissimilarities as weights\n",
        "for pair, distance in distances.items():\n",
        "    class1, class2 = pair.split(' vs ')\n",
        "\n",
        "    # Add edge between the classes with distance as weight\n",
        "    G.add_edge(class1, class2, weight=distance)\n",
        "\n",
        "# Find the maximum weight matching in the graph\n",
        "max_matching = nx.max_weight_matching(G, maxcardinality=True, weight='weight')\n",
        "\n",
        "# Print out the matched pairs (i.e., the tasks)\n",
        "print(\"Tasks with maximized dissimilarities:\")\n",
        "for task in max_matching:\n",
        "    print(f\"Task: {task}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2a88139",
      "metadata": {
        "id": "f2a88139"
      },
      "outputs": [],
      "source": [
        "final_groups = {0: ['8 - eight', '2 - two'],\n",
        " 1: ['4 - four', '0 - zero'],\n",
        " 2: ['3 - three', '1 - one'],\n",
        " 3: ['9 - nine', '5 - five'],\n",
        " 4: ['6 - six', '7 - seven']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac51aec6",
      "metadata": {
        "id": "ac51aec6"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_task = 5\n",
        "task_similarity = [[0 for _ in range(num_task)] for _ in range(num_task)]\n",
        "re = distances\n",
        "for i in range(num_task):\n",
        "    for j in range(num_task):\n",
        "        if i == j:\n",
        "            continue  # Skip comparing the task with itself\n",
        "        # Calculate average distance between classes in task i and task j\n",
        "        total_distance = 0\n",
        "        count = 0\n",
        "        for class1 in final_groups[i]:\n",
        "            for class2 in final_groups[j]:\n",
        "                key = f\"{class1} vs {class2}\" if f\"{class1} vs {class2}\" in re else f\"{class2} vs {class1}\"\n",
        "                total_distance += re[key]\n",
        "                count += 1\n",
        "        average_distance = total_distance / count\n",
        "        task_similarity[i][j] = average_distance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cc5996e",
      "metadata": {
        "id": "7cc5996e",
        "outputId": "b74a9308-d7a3-41cd-9138-b748fcbb1e90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0, 0.23935, 0.2583, 0.19849999999999998, 0.22472499999999998],\n",
              " [0.23935, 0, 0.2768, 0.24092500000000003, 0.246675],\n",
              " [0.2583, 0.2768, 0, 0.24357499999999999, 0.25215],\n",
              " [0.1985, 0.240925, 0.24357499999999999, 0, 0.20190000000000002],\n",
              " [0.22472499999999998, 0.24667499999999998, 0.25215, 0.2019, 0]]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "task_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1864fe88",
      "metadata": {
        "id": "1864fe88",
        "outputId": "90313547-13fd-49bc-ddac-049681d2a01b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Suggested task order to minimize distribution changes: [0, 3, 4, 1, 2]\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "task_order = greedy_nearest_neighbors(task_similarity)\n",
        "\n",
        "print(\"Suggested task order to minimize distribution changes:\", task_order)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}